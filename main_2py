### Portfolio Optiimization
### Sean Welleck | 2014
#
# Finds an optimal allocation of stocks in a portfolio,
# satisfying a minimum expected return.
# The problem is posed as a Quadratic Program, and solved
# using the cvxopt library.
# Uses actual past stock data, obtained using the stocks module.
import math
import numpy as np
import pandas as pd
import datetime
import cvxopt
from cvxopt import matrix, solvers
import matplotlib.pyplot as plt
##########################
import warnings
warnings.filterwarnings('ignore')
warnings.warn('DelftStack')
warnings.warn('Do not show this message')
#####################
solvers.options['show_progress'] = False        # !!!

pd.set_option('display.max_rows', 500)
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 1000)

#from cvxopt import solvers
#import stocks
import numpy
import pandas as pd

# c = cvxopt.matrix([0, -1], tc='d')
# print('c: ', c)
# c = numpy.matrix(c)
# print('c: ', c)
#
# c = cvxopt.matrix([0, -1])
# print('c: ', c)
# G = cvxopt.matrix([[-1, 1], [3, 2], [2, 3], [-1, 0], [0, -1]], tc='d')
# print('G: ', G)
##################
xDir = r'D:\\Users\\ggu\\Documents\\GU\\MeanVarianceOptimization\\'
xSPXT = pd.read_csv(xDir + 'SPXT.txt')
xSPXT['DATE'] = pd.to_datetime(xSPXT['DATE'], format='%m/%d/%Y')
xAggregateBondTR = pd.read_csv(xDir + 'AggregateBondTR.txt')
xAggregateBondTR['DATE'] = pd.to_datetime(xAggregateBondTR['DATE'], format='%m/%d/%Y')

# xSI = pd.read_csv(xDir + 'SI.txt')
# xSI['DATE'] = pd.to_datetime(xSI['DATE'], format='%m/%d/%Y')

xSPX = pd.read_csv(xDir + 'SPX.txt')
xSPX['DATE'] = pd.to_datetime(xSPX['DATE'], format='%m/%d/%Y')

##xAggregateBondTR = pd.read_csv(xDir + 'AggregateBondTR.txt')

print(xSPXT.head())
print(xAggregateBondTR.head())
#print(xSI.head())
print(xSPX.head())

# xSPXT = pd.merge(xSPXT, xSI, on=['DATE'], how='left')
xSPXT = pd.merge(xSPXT, xAggregateBondTR, on=['DATE'], how='left')
xSPXT = pd.merge(xSPXT, xSPX, on=['DATE'], how='left')

# xMinDateSI = xSI['DATE'].min()
# xMaxDateSI = xSI['DATE'].max()

###xSPXT = xSPXT.loc[(xSPXT['DATE'] >= xMinDateSI) & (xSPXT['DATE'] <= xMaxDateSI)]

#xSPXT['intrinsic_value'].fillna(method='ffill', inplace=True) #fill N/As with previous prices!!!!
xSPXT['LBUSTRUU'].fillna(method='ffill', inplace=True) #fill N/As with previous prices!!!!
xSPXT['SPX'].fillna(method='ffill', inplace=True)

xSPXT['SPXT_rtn'] = xSPXT['SPXT'].pct_change()
#xSPXT['SI_rtn'] = xSPXT['intrinsic_value'].pct_change()
xSPXT['Bond_rtn'] = xSPXT['LBUSTRUU'].pct_change()
xSPXT['SPX_rtn'] = xSPXT['SPX'].pct_change()

xSPXT.to_csv(xDir + 'xSPXT.txt')

xSPXT = xSPXT.dropna()
########################
xUnderlier = 'SPX'

xDF0 = xSPXT[['DATE', xUnderlier]]
print('xDF0 = ', xDF0.head())

### These are the generic products we used in learning center.
#-	2Y, 10% hard buffer, 1.5x upside up to 21%
#-	4Y, 25% barrier, 1x upside no-cap
#-	6Y, 30% barrier, 1.15x upside no-cap
#################################################################

xCap = 1000  #0.21
xBuffer = -0.10   #-0.25
xDate = '2000-01-01'
xTerm = 2  #2  #4  #6   #4 #2  #3 # years
xAmount = 100000
xLever = 1.50  #1.15
xBufferType = "H"  #"T"  # "H" for regular Buffer; "G" for Geared Buffer (or Barrier); "T" for Trigger Buffer!
xStartDate = datetime.date.fromisoformat(xDate)
print('start date = ', xStartDate)
xPortfolio = pd.DataFrame()

####################

xEndDate = xStartDate + datetime.timedelta(days = 365*xTerm)
print('xEndDate = ', xEndDate)
xDF = xDF0.loc[(xDF0['DATE'] >= xStartDate.strftime('%Y-%m-%d')) & (xDF0['DATE'] <= xEndDate.strftime('%Y-%m-%d'))]
xDF.reset_index(drop=True, inplace=True)
###### in case xEndDate does NOT exist in xDF, then reassign the latest date less than the original xEndDate ###
xEndDate = xDF.loc[xDF.index == (len(xDF)-1)]['DATE'][len(xDF)-1]

xTime = 0
xString3 = 'Structure: ' + 'Buffer Type = ' + xBufferType + '; Term = ' + (str)(xTerm) + ' years; ' + (str)(xLever) + 'x Underlier; Cap = '  + (str)(xCap) + '; Buffer = ' + (str)(xBuffer)
xStartDate0 = xStartDate
###while (xDF.empty != True):	#this may not work properly because xStartDate = xEndDate = 1 row onlu!!!!
while (xStartDate != xEndDate):
	print('start date = ', xStartDate, ';    end date = ', xEndDate)
	xTime = xTime + 1

	xStartValue = xDF.loc[xDF.index==0][xUnderlier][0]
	xDF['CumRtn_UL'] = xDF[xUnderlier] / xStartValue - 1
	xDF['CumRtn_SI'] = xDF['CumRtn_UL'].copy()
	############# simple buffer for DOWNSIDE ########
	xDF.loc[(xDF['CumRtn_UL']<0) & (xDF['CumRtn_UL']>xBuffer), 'CumRtn_SI'] = 0
	if (xBufferType == "H"):
		xDF.loc[(xDF['CumRtn_UL'] <= xBuffer), 'CumRtn_SI'] = xDF['CumRtn_UL'] - xBuffer
	elif (xBufferType == "T"):
		# do nothing here for trigger buffer
		print("Trigger Buffer here...")
	else:
		# do geared buffer here
		print("Geared Buffer here...")

	############# leverage for UPSIDE ##############
	xDF.loc[(xDF['CumRtn_SI'] > 0), 'CumRtn_SI'] = xDF['CumRtn_SI'] * xLever
	############# simple cap for UPSIDE (after LEVERAGE) ###########
	xDF.loc[(xDF['CumRtn_SI'] >= xCap), 'CumRtn_SI'] = xCap

	############# calculate IV and Portfolio Values (PV) ########
	xDF['IV'] = xStartValue * (1 + xDF['CumRtn_SI'])
	xDF['PV_SI'] = xDF['IV'] / xStartValue * xAmount / 2
	xDF['PV_UL'] = xDF[xUnderlier] / xStartValue * xAmount / 2

	xDF['PV'] = xDF['PV_SI'] + xDF['PV_UL']
	############### calculate daily returns ##################
	xDF[xUnderlier+'_rtn'] = xDF[xUnderlier].pct_change()
	xDF['IV_rtn'] = xDF['IV'].pct_change()
	xDF['SI_rtn'] = xDF['PV_SI'].pct_change()
	xDF['UL_rtn'] = xDF['PV_UL'].pct_change()
	xDF['PV_rtn'] = xDF['PV'].pct_change()
	########### calculate the downside risks ################
	xDF[xUnderlier + '_rtnSQ'] = xDF[xUnderlier+'_rtn'] - xDF[xUnderlier+'_rtn'].mean()
	xDF['IV_rtnSQ'] = xDF['IV_rtn'] - xDF['IV_rtn'].mean()
	xDF['SI_rtnSQ'] = xDF['SI_rtn'] - xDF['SI_rtn'].mean()
	xDF['UL_rtnSQ'] = xDF['UL_rtn'] - xDF['UL_rtn'].mean()
	xDF['PV_rtnSQ'] = xDF['PV_rtn'] - xDF['PV_rtn'].mean()

	xDF.loc[(xDF[xUnderlier + '_rtnSQ'] > 0), xUnderlier + '_rtnSQ'] = 0
	xDF.loc[(xDF['IV_rtnSQ'] > 0), 'IV_rtnSQ'] = 0
	xDF.loc[(xDF['SI_rtnSQ'] > 0), 'SI_rtnSQ'] = 0
	xDF.loc[(xDF['UL_rtnSQ'] > 0), 'UL_rtnSQ'] = 0
	xDF.loc[(xDF['PV_rtnSQ'] > 0), 'PV_rtnSQ'] = 0

	xDF[xUnderlier + '_rtnSQ'] = xDF[xUnderlier + '_rtnSQ'] ** 2
	xDF['IV_rtnSQ'] = xDF['IV_rtnSQ'] ** 2
	xDF['SI_rtnSQ'] = xDF['SI_rtnSQ'] ** 2
	xDF['UL_rtnSQ'] = xDF['UL_rtnSQ'] ** 2
	xDF['PV_rtnSQ'] = xDF['PV_rtnSQ'] ** 2

	globals()['xDnRisk_' + xUnderlier] = np.sqrt(xDF[xUnderlier + '_rtnSQ'].mean() * 252)
	xDnRisk_IV = np.sqrt(xDF['IV_rtnSQ'].mean() * 252)
	xDnRisk_SI = np.sqrt(xDF['SI_rtnSQ'].mean() * 252)
	xDnRisk_UL = np.sqrt(xDF['UL_rtnSQ'].mean() * 252)
	xDnRisk_PV = np.sqrt(xDF['PV_rtnSQ'].mean() * 252)

	######### calculate days and compounded returns, std of returns, correlation, sharp ratio, etc...###
	######### calculate other statistics here .............
	xDF.reset_index(drop=True, inplace=True)
	xDays = (xDF.loc[xDF.index == (len(xDF)-1)]['DATE'][len(xDF)-1] - xDF.loc[xDF.index == 0]['DATE'][0]).days
	# ############### the following has some problem by using start value and end value with rebalancing #####
	# ######## it must be using daily returns ###############
	# xFirst_PV_SI = xDF.loc[xDF.index == 0]['PV_SI'][0]
	# xLast_PV_SI = xDF.loc[xDF.index == (len(xDF) - 1)]['PV_SI'][len(xDF) - 1]
	# xFirst_PV_UL = xDF.loc[xDF.index == 0]['PV_UL'][0]
	# xLast_PV_UL = xDF.loc[xDF.index == (len(xDF) - 1)]['PV_UL'][len(xDF) - 1]
	# xFirst_PV = xDF.loc[xDF.index == 0]['PV'][0]
	# xLast_PV = xDF.loc[xDF.index == (len(xDF) - 1)]['PV'][len(xDF) - 1]
	#globals()['xFirst_'+xUnderlier] = xDF.loc[xDF.index == 0][xUnderlier][0]
	#globals()['xLast_'+xUnderlier] = xDF.loc[xDF.index == (len(xDF) - 1)][xUnderlier][len(xDF) - 1]
	#########################
	xDF['temp'] = (1 + xDF[xUnderlier + '_rtn']).cumprod()
	globals()['xCM_rtn_' + xUnderlier] = xDF['temp'][len(xDF) - 1]
	xDF['temp'] = (1 + xDF['IV_rtn']).cumprod()
	xCM_rtn_IV = xDF['temp'][len(xDF) - 1]
	xDF['temp'] = (1 + xDF['SI_rtn']).cumprod()
	xCM_rtn_SI = xDF['temp'][len(xDF) - 1]
	xDF['temp'] = (1 + xDF['UL_rtn']).cumprod()
	xCM_rtn_UL = xDF['temp'][len(xDF) - 1]
	xDF['temp'] = (1 + xDF['PV_rtn']).cumprod()
	xCM_rtn_PV = xDF['temp'][len(xDF) - 1]

	xCAGR_SI = (xCM_rtn_SI) ** (1 / (xDays / 365)) - 1
	xCAGR_UL = (xCM_rtn_UL) ** (1 / (xDays / 365)) - 1
	xCAGR_PV = (xCM_rtn_PV) ** (1 / (xDays / 365)) - 1
	globals()['xCAGR_' + xUnderlier] = (globals()['xCM_rtn_' + xUnderlier]) ** (1 / (xDays / 365)) - 1

	xSimple_rtn_SI = xCM_rtn_SI - 1.0
	xSimple_rtn_UL = xCM_rtn_UL - 1.0
	xSimple_rtn_PV = xCM_rtn_PV - 1.0
	globals()['xSimple_rtn_' + xUnderlier] = globals()['xCM_rtn_' + xUnderlier] - 1.0

	xMean = pd.DataFrame(xDF[['SI_rtn', 'UL_rtn', 'PV_rtn', 'SPX_rtn']].mean(), columns=['AvgDlyRtn'])
	xStd = pd.DataFrame(xDF[['SI_rtn', 'UL_rtn', 'PV_rtn', 'SPX_rtn']].std() * math.sqrt(252), columns=['AnnStd'])
	xMax = pd.DataFrame(xDF[['SI_rtn', 'UL_rtn', 'PV_rtn', 'SPX_rtn']].max(), columns=['Max'])
	xMin = pd.DataFrame(xDF[['SI_rtn', 'UL_rtn', 'PV_rtn', 'SPX_rtn']].min(), columns=['Min'])

	xStats = pd.merge(xMean, xStd, left_index=True, right_index=True)
	xStats = pd.merge(xStats, xMax, left_index=True, right_index=True)
	xStats = pd.merge(xStats, xMin, left_index=True, right_index=True)

	xStats['AnnRtn'] = xCAGR_SI
	xStats['AnnRtn']['UL_rtn'] = xCAGR_UL
	xStats['AnnRtn']['PV_rtn'] = xCAGR_PV
	xStats['AnnRtn'][xUnderlier + '_rtn'] = globals()['xCAGR_' + xUnderlier]

	xStats['SimpleRtn'] = xSimple_rtn_SI
	xStats['SimpleRtn']['UL_rtn'] = xSimple_rtn_UL
	xStats['SimpleRtn']['PV_rtn'] = xSimple_rtn_PV
	xStats['SimpleRtn'][xUnderlier + '_rtn'] = globals()['xSimple_rtn_' + xUnderlier]

	xStats['AnnDnRisk'] = xDnRisk_SI
	xStats['AnnDnRisk']['UL_rtn'] = xDnRisk_UL
	xStats['AnnDnRisk']['PV_rtn'] = xDnRisk_PV
	xStats['AnnDnRisk'][xUnderlier + '_rtn'] = globals()['xDnRisk_' + xUnderlier]

	xStats['Sharpe'] = xStats['AnnRtn'] / xStats['AnnStd']
	xStats['SharpeDnRisk'] = xStats['AnnRtn'] / xStats['AnnDnRisk']

	############# format output #############
	xStats['AvgDlyRtn'] = xStats['AvgDlyRtn'].astype(float).map("{:.3%}".format)
	xStats['AnnStd'] = xStats['AnnStd'].astype(float).map("{:.2%}".format)
	xStats['Max'] = xStats['Max'].astype(float).map("{:.2%}".format)
	xStats['Min'] = xStats['Min'].astype(float).map("{:.2%}".format)
	xStats['AnnRtn'] = xStats['AnnRtn'].astype(float).map("{:.3%}".format)
	xStats['SimpleRtn'] = xStats['SimpleRtn'].astype(float).map("{:.2%}".format)
	xStats['AnnDnRisk'] = xStats['AnnDnRisk'].astype(float).map("{:.2%}".format)

	xStats = np.round(xStats, 4)
	xCorrMatrix = np.round(xDF[['SI_rtn', (xUnderlier+'_rtn'), 'PV_rtn']].corr(), 4)

	xString0 = 'From ' + xStartDate.strftime('%m/%d/%Y') + ' to ' + xEndDate.strftime('%m/%d/%Y')
	xString1 = xStats.astype('string')
	xString2 = xCorrMatrix.astype('string')

	xString = (str)(xString0) + '\n\n' + (str)(xString1) + '\n\n'+(str)(xString2)
	xString3 = xString3 + '\n\n' + xString
	############ end of calculating statistics ##################
	#############################################################
	xDF.to_csv(xDir + 'xBufferIV_' + str(xTime) + '_' + xBufferType + '.txt')
	##############
	####### combine together while rolling over #####
	if xTime > 1:
		xDF = xDF[1:]  # remove the first row, it is duplicated with the last row of previous xDF !!!
		xDF.reset_index(drop=True, inplace=True)
	xPortfolio = pd.concat([xPortfolio, xDF], ignore_index=True)
	### reassign or reset for the next new SI to start ########
	xAmount = xDF['PV'][len(xDF)-1]
	xStartDate = xEndDate

	############## NEW xDF here from the original xDF0 ###############
	xDF = xDF0.loc[xDF0['DATE']>=xStartDate.strftime('%Y-%m-%d')]
	#xDF.reset_index(drop=True, inplace=True)
	#xStartValue = xDF.loc[xDF.index == 0][xUnderlier][0]

	xEndDate = xStartDate + datetime.timedelta(days = 365 * xTerm)
	xDF = xDF.loc[(xDF['DATE'] <= xEndDate.strftime('%Y-%m-%d'))]
	xDF.reset_index(drop=True, inplace=True)
	xEndDate = xDF.loc[xDF.index == (len(xDF)-1)]['DATE'][len(xDF)-1]

############################################################
xPortfolio.to_csv(xDir + 'xBufferIV' + '_' + xBufferType + '.txt')
if True:
	######### calculate days and compounded returns, std of returns, correlation, sharp ratio, etc...###
	######### calculate other statistics here .............
	xPortfolio.reset_index(drop=True, inplace=True)
	########### calculate the downside risks ################
	xPortfolio[xUnderlier + '_rtnSQ'] = xPortfolio[xUnderlier + '_rtn'] - xPortfolio[xUnderlier + '_rtn'].mean()
	xPortfolio['IV_rtnSQ'] = xPortfolio['IV_rtn'] - xPortfolio['IV_rtn'].mean()
	xPortfolio['SI_rtnSQ'] = xPortfolio['SI_rtn'] - xPortfolio['SI_rtn'].mean()
	xPortfolio['UL_rtnSQ'] = xPortfolio['UL_rtn'] - xPortfolio['UL_rtn'].mean()
	xPortfolio['PV_rtnSQ'] = xPortfolio['PV_rtn'] - xPortfolio['PV_rtn'].mean()

	xPortfolio.loc[(xPortfolio[xUnderlier + '_rtnSQ'] > 0), xUnderlier + '_rtnSQ'] = 0
	xPortfolio.loc[(xPortfolio['IV_rtnSQ'] > 0), 'IV_rtnSQ'] = 0
	xPortfolio.loc[(xPortfolio['SI_rtnSQ'] > 0), 'SI_rtnSQ'] = 0
	xPortfolio.loc[(xPortfolio['UL_rtnSQ'] > 0), 'UL_rtnSQ'] = 0
	xPortfolio.loc[(xPortfolio['PV_rtnSQ'] > 0), 'PV_rtnSQ'] = 0

	xPortfolio[xUnderlier + '_rtnSQ'] = xPortfolio[xUnderlier + '_rtnSQ'] ** 2
	xPortfolio['IV_rtnSQ'] = xPortfolio['IV_rtnSQ'] ** 2
	xPortfolio['SI_rtnSQ'] = xPortfolio['SI_rtnSQ'] ** 2
	xPortfolio['UL_rtnSQ'] = xPortfolio['UL_rtnSQ'] ** 2
	xPortfolio['PV_rtnSQ'] = xPortfolio['PV_rtnSQ'] ** 2

	globals()['xDnRisk_' + xUnderlier] = np.sqrt(xPortfolio[xUnderlier + '_rtnSQ'].mean() * 252)
	xDnRisk_IV = np.sqrt(xPortfolio['IV_rtnSQ'].mean() * 252)
	xDnRisk_SI = np.sqrt(xPortfolio['SI_rtnSQ'].mean() * 252)
	xDnRisk_UL = np.sqrt(xPortfolio['UL_rtnSQ'].mean() * 252)
	xDnRisk_PV = np.sqrt(xPortfolio['PV_rtnSQ'].mean() * 252)
	###########################
	xDays = (xPortfolio.loc[xPortfolio.index == (len(xPortfolio)-1)]['DATE'][len(xPortfolio)-1] - xPortfolio.loc[xPortfolio.index == 0]['DATE'][0]).days
	# xFirst_PV_SI = xPortfolio.loc[xPortfolio.index == 0]['PV_SI'][0]
	# xLast_PV_SI = xPortfolio.loc[xPortfolio.index == (len(xPortfolio) - 1)]['PV_SI'][len(xPortfolio) - 1]
	# xFirst_PV_UL = xPortfolio.loc[xPortfolio.index == 0]['PV_UL'][0]
	# xLast_PV_UL = xPortfolio.loc[xPortfolio.index == (len(xPortfolio) - 1)]['PV_UL'][len(xPortfolio) - 1]
	# xFirst_PV = xPortfolio.loc[xPortfolio.index == 0]['PV'][0]
	# xLast_PV = xPortfolio.loc[xPortfolio.index == (len(xPortfolio) - 1)]['PV'][len(xPortfolio) - 1]
	# globals()['xFirst_'+xUnderlier] = xPortfolio.loc[xPortfolio.index == 0][xUnderlier][0]
	# globals()['xLast_'+xUnderlier] = xPortfolio.loc[xPortfolio.index == (len(xPortfolio) - 1)][xUnderlier][len(xPortfolio) - 1]

	#########################
	xPortfolio['temp'] = (1 + xPortfolio[xUnderlier + '_rtn']).cumprod()
	globals()['xCM_rtn_' + xUnderlier] = xPortfolio['temp'][len(xPortfolio) - 1]
	xPortfolio['temp'] = (1 + xPortfolio['IV_rtn']).cumprod()
	xCM_rtn_IV = xPortfolio['temp'][len(xPortfolio) - 1]
	xPortfolio['temp'] = (1 + xPortfolio['SI_rtn']).cumprod()
	xCM_rtn_SI = xPortfolio['temp'][len(xPortfolio) - 1]
	xPortfolio['temp'] = (1 + xPortfolio['UL_rtn']).cumprod()
	xCM_rtn_UL = xPortfolio['temp'][len(xPortfolio) - 1]
	xPortfolio['temp'] = (1 + xPortfolio['PV_rtn']).cumprod()
	xCM_rtn_PV = xPortfolio['temp'][len(xPortfolio) - 1]

	xCAGR_SI = (xCM_rtn_SI) ** (1 / (xDays / 365)) - 1
	xCAGR_UL = (xCM_rtn_UL) ** (1 / (xDays / 365)) - 1
	xCAGR_PV = (xCM_rtn_PV) ** (1 / (xDays / 365)) - 1
	globals()['xCAGR_' + xUnderlier] = (globals()['xCM_rtn_' + xUnderlier]) ** (1 / (xDays / 365)) - 1

	xSimple_rtn_SI = xCM_rtn_SI - 1.0
	xSimple_rtn_UL = xCM_rtn_UL - 1.0
	xSimple_rtn_PV = xCM_rtn_PV - 1.0
	globals()['xSimple_rtn_' + xUnderlier] = globals()['xCM_rtn_' + xUnderlier] - 1.0

	xMean = pd.DataFrame(xPortfolio[['SI_rtn', 'UL_rtn', 'PV_rtn', 'SPX_rtn']].mean(), columns=['AvgDlyRtn'])
	xStd = pd.DataFrame(xPortfolio[['SI_rtn', 'UL_rtn', 'PV_rtn', 'SPX_rtn']].std() * math.sqrt(252), columns=['AnnStd'])
	xMax = pd.DataFrame(xPortfolio[['SI_rtn', 'UL_rtn', 'PV_rtn', 'SPX_rtn']].max(), columns=['Max'])
	xMin = pd.DataFrame(xPortfolio[['SI_rtn', 'UL_rtn', 'PV_rtn', 'SPX_rtn']].min(), columns=['Min'])

	xStats = pd.merge(xMean, xStd, left_index=True, right_index=True)
	xStats = pd.merge(xStats, xMax, left_index=True, right_index=True)
	xStats = pd.merge(xStats, xMin, left_index=True, right_index=True)

	xStats['AnnRtn'] = xCAGR_SI
	xStats['AnnRtn']['UL_rtn'] = xCAGR_UL
	xStats['AnnRtn']['PV_rtn'] = xCAGR_PV
	xStats['AnnRtn'][xUnderlier + '_rtn'] = globals()['xCAGR_' + xUnderlier]

	xStats['SimpleRtn'] = xSimple_rtn_SI
	xStats['SimpleRtn']['UL_rtn'] = xSimple_rtn_UL
	xStats['SimpleRtn']['PV_rtn'] = xSimple_rtn_PV
	xStats['SimpleRtn'][xUnderlier + '_rtn'] = globals()['xSimple_rtn_' + xUnderlier]

	xStats['AnnDnRisk'] = xDnRisk_SI
	xStats['AnnDnRisk']['UL_rtn'] = xDnRisk_UL
	xStats['AnnDnRisk']['PV_rtn'] = xDnRisk_PV
	xStats['AnnDnRisk'][xUnderlier + '_rtn'] = globals()['xDnRisk_' + xUnderlier]

	xStats['Sharpe'] = xStats['AnnRtn'] / xStats['AnnStd']
	xStats['SharpeDnRisk'] = xStats['AnnRtn'] / xStats['AnnDnRisk']
	############# format output #############
	xStats['AvgDlyRtn'] = xStats['AvgDlyRtn'].astype(float).map("{:.3%}".format)
	xStats['AnnStd'] = xStats['AnnStd'].astype(float).map("{:.2%}".format)
	xStats['Max'] = xStats['Max'].astype(float).map("{:.2%}".format)
	xStats['Min'] = xStats['Min'].astype(float).map("{:.2%}".format)
	xStats['AnnRtn'] = xStats['AnnRtn'].astype(float).map("{:.3%}".format)
	xStats['SimpleRtn'] = xStats['SimpleRtn'].astype(float).map("{:.2%}".format)
	xStats['AnnDnRisk'] = xStats['AnnDnRisk'].astype(float).map("{:.2%}".format)

	xStats = np.round(xStats, 4)
	xCorrMatrix = np.round(xPortfolio[['SI_rtn',(xUnderlier+'_rtn'),'PV_rtn']].corr(), 4)

	xString0 = '****** From ' + xStartDate0.strftime('%m/%d/%Y') + ' to ' + xEndDate.strftime('%m/%d/%Y') + ' ******'
	xString1 = xStats.astype('string')
	xString2 = xCorrMatrix.astype('string')

	xString = (str)(xString0) + '\n\n' + (str)(xString1) + '\n\n'+(str)(xString2)
	xString3 = xString3 + '\n\n\n\n' + xString
	############ end of calculating statistics ##################
	#############################################################
	f_w = open(xDir + 'xStats_all_' + xBufferType + '.txt','w')
	f_w.write(xString3)
	f_w.close()

